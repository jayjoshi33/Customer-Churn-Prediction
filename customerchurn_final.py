# -*- coding: utf-8 -*-
"""CustomerChurn_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Urj5SBKw3e3kFL6WsQf9rWFfw5EZDGD4
"""

from google.colab import drive
drive.mount('/content/drive/')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
sns.set()

from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,recall_score
from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc,f1_score
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb

data=pd.read_csv('/content/drive/MyDrive/# Datasets-20240726T040953Z-001/# Datasets/customer_churn.csv')

df=data.copy()

"""##Understanding the data

#####How data looks like?
"""

df.head(8)

"""#####What is size of data?"""

df.shape

"""#####What are the column types?"""

df.info()

"""#####How data is mathmatically?"""

pd.set_option('display.float_format', '{:.2f}'.format)
df.describe().T

"""#####Are there any missing values?"""

df.isnull().sum()

"""#####Are there any duplicate rows?"""

df.duplicated().sum()

"""###How are the categorical features?"""

df['Surname'].value_counts()

df['Geography'].value_counts()

df['Gender'].value_counts()

"""#####Is data imbalanced?"""

exited=df['Exited'].value_counts()
plt.figure(figsize=(5,5))
sns.barplot(x=exited.index,y=exited,color='r')
plt.xlabel('Exited')
plt.ylabel('Count')
plt.show()

"""##Distribution of the input feautres"""

plt.figure(figsize=(5,5))
sns.countplot(x='Gender',data=df,color='g')
plt.show()

plt.figure(figsize=(5,5))
sns.countplot(x='Geography',data=df,color='c')
plt.show()

plt.figure(figsize=(5,5))
sns.countplot(x='HasCrCard',data=df,color='y')
plt.show()

plt.figure(figsize=(5,5))
sns.countplot(x='Tenure',data=df,color='m')
plt.show()

mem=df['IsActiveMember'].value_counts()
plt.figure(figsize=(5,5))
sns.barplot(x=mem.index,y=mem)
plt.xlabel('IsActiveMember')
plt.ylabel('Count')
plt.show()

mem=df['NumOfProducts'].value_counts()
plt.figure(figsize=(5,5))
sns.barplot(x=mem.index,y=mem,color='#FFA500')
plt.xlabel('NumOfProducts')
plt.ylabel('Count')
plt.show()

sns.distplot(df['Age'],kde=True)

sns.displot(df['Age'],kind='ecdf',color='r')

sns.displot(df['EstimatedSalary'],kde=True)

sns.displot(df['Balance'],kde=True)

sns.displot(df['Balance'],kind='ecdf',color='r')

"""##Multivariate analysis

"""

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['Gender'],palette='Accent')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['HasCrCard'],palette='Pastel1')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['NumOfProducts'],palette='Set3')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['Geography'],palette='plasma')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['IsActiveMember'],palette='viridis')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['Tenure'],palette='Set1')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(x=df['Exited'],y=df['Balance'],palette='Set2')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(x=df['Exited'],y=df['Age'],palette='Set3')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(x=df['Exited'],y=df['CreditScore'],palette='spring')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['Gender'],hue=df['Geography'],palette='Pastel2')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['Gender'],hue=df['IsActiveMember'],palette='Blues')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['Geography'],hue=df['IsActiveMember'],palette='cividis')
plt.show()

plt.figure(figsize=(5,5))
sns.barplot(y=df['Exited'],x=df['NumOfProducts'],hue=df['IsActiveMember'],palette='inferno')
plt.show()

cols=['NumOfProducts','Tenure','Balance','Age','CreditScore','EstimatedSalary']
def plot_boxplots(df):
    for column in cols:
        plt.figure(figsize=(5, 5))  # Set the figure size
        sns.boxplot(x=df[column], color='r')  # Plot the boxplot for the column
        plt.title(f'Boxplot for {column}')  # Set title for each plot
        plt.show()  # Show the plot

plot_boxplots(df)

"""##Data Preprocessing"""

#There are 2932 unique surnames so it will be very difficult to use it as a feature.So we will remove this feature.
df.drop('Surname',axis=1,inplace=True)

df.drop('Row Number',axis=1,inplace=True)
df.drop('Customer Id',axis=1,inplace=True)

df_cleaned = df[df['Age'] <= 60]

# correlation_matrix = df.corr()

# # Create a heatmap
# plt.figure(figsize=(10, 8))
# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
# plt.title('Correlation Heatmap')
# plt.show()



"""# Distance based algorithms"""

X=df_cleaned.drop('Exited',axis=1)
y=df_cleaned['Exited']
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)

def fit_transform_ohe_X_train(X_train, columns_to_encode, desired_order):
    # Initialize OneHotEncoder
    ohe = OneHotEncoder(drop='first', sparse=False)

    # Fit and transform the specified categorical columns
    encoded_columns_train = ohe.fit_transform(X_train[columns_to_encode])

    # Get new column names after encoding
    encoded_column_names = ohe.get_feature_names_out(columns_to_encode)

    # Create a DataFrame with the encoded columns
    encoded_X_train = pd.DataFrame(encoded_columns_train, columns=encoded_column_names)

    # Drop original categorical columns from X_train
    X_train = X_train.drop(columns_to_encode, axis=1)

    # Concatenate the original DataFrame with the encoded DataFrame
    X_train_encoded = pd.concat([X_train.reset_index(drop=True), encoded_X_train.reset_index(drop=True)], axis=1)

    # Reorder the columns according to the desired order
    X_train_encoded = X_train_encoded[desired_order]

    return X_train_encoded, ohe

columns_to_encode = ['Geography', 'Gender']
desired_order = ['CreditScore', 'Geography_Germany', 'Geography_Spain', 'Gender_Male', 'Age', 'Tenure',
                 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']

# Fit and transform the training data, reorder columns
X_train, ohe = fit_transform_ohe_X_train(X_train, columns_to_encode, desired_order)

def transform_ohe_X_test(X_test, encoder, columns_to_encode, desired_order):
    encoded_columns_test = encoder.transform(X_test[columns_to_encode])

    # Get new column names after encoding
    encoded_column_names = encoder.get_feature_names_out(columns_to_encode)

    # Create a DataFrame with the encoded columns
    encoded_X_test = pd.DataFrame(encoded_columns_test, columns=encoded_column_names)

    # Drop original categorical columns from X_test
    X_test = X_test.drop(columns_to_encode, axis=1)

    # Concatenate the original DataFrame with the encoded DataFrame
    X_test_encoded = pd.concat([X_test.reset_index(drop=True), encoded_X_test.reset_index(drop=True)], axis=1)

    # Reorder the columns according to the desired order
    X_test_encoded = X_test_encoded[desired_order]

    return X_test_encoded

# Transform the test data using the fitted encoder and reorder columns
X_test = transform_ohe_X_test(X_test, ohe, columns_to_encode, desired_order)

features_to_scale = ['CreditScore', 'Balance', 'EstimatedSalary', 'Age']

# Initialize a single StandardScaler
scaler = StandardScaler()

# Fit the scaler on the training data and transform it
X_train_scaled = X_train.copy()  # Copy original DataFrame to keep the structure intact
X_train_scaled[features_to_scale] = scaler.fit_transform(X_train[features_to_scale])

# Transform the test data using the same scaler (without fitting again)
X_test_scaled = X_test.copy()  # Copy original DataFrame to keep the structure intact
X_test_scaled[features_to_scale] = scaler.transform(X_test[features_to_scale])

"""###Logistic Regression"""

lr=LogisticRegression()

param_grid_lr={'C':[0.001,0.01,0.1,1,10,100,1000],
              'penalty':['l1','l2'],
              'solver':['liblinear']}
grid_lr=GridSearchCV(estimator=lr,param_grid=param_grid_lr,cv=5,scoring='accuracy',verbose=2)
grid_lr.fit(X_train_scaled,y_train)

grid_lr.best_params_

"""###SVC"""

svc=SVC()

param_grid_svc = {'C': [0.1,0.5, 1,10],
                  'kernel': ['linear', 'rbf'],
                  'gamma': ['scale', 'auto']}
grid_svc=GridSearchCV(estimator=svc,param_grid=param_grid_svc,cv=5,scoring='accuracy',verbose=1)
grid_svc.fit(X_train_scaled,y_train)

grid_svc.best_params_

"""###Naive bayes"""

nb=GaussianNB()
param_grid_nb = {
    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]  # variance smoothing hyperparameter
}

# Initialize GridSearchCV
grid_nb = GridSearchCV(estimator=nb, param_grid=param_grid_nb, cv=5, scoring='accuracy')

# Fit the model
grid_nb.fit(X_train_scaled, y_train)

grid_nb.best_params_

"""###KNN"""

knn=KNeighborsClassifier()

param_grid_knn = {
    'n_neighbors': [3, 5, 7, 9, 11],  # Number of neighbors to use
    'weights': ['uniform', 'distance'],  # Weight function used in prediction
    'metric': ['euclidean', 'manhattan', 'minkowski'],  # Distance metrics
    'p': [1, 2]  # Power parameter for the Minkowski metric (only applies to 'minkowski' metric)
}

# Initialize GridSearchCV
grid_knn = GridSearchCV(estimator=knn, param_grid=param_grid_knn, cv=5, scoring='accuracy')

# Fit the model
grid_knn.fit(X_train_scaled, y_train)

grid_knn.best_params_

"""# Tree-based algorithmns

###Decision Tree
"""

dt=DecisionTreeClassifier()

param_grid_dt = {'max_depth':[3,5,7,10,15],
          'min_samples_leaf':[3,5,10,15,20],
          'min_samples_split':[8,10,12,18,20,16],
          'criterion':['gini','entropy']}

grid_dt = GridSearchCV(estimator=dt, param_grid=param_grid_dt, cv=5,scoring='accuracy',verbose=1)
grid_dt.fit(X_train, y_train)
grid_search_dt = grid_dt.best_estimator_

grid_dt.best_params_

"""###Random Forest"""

rf=RandomForestClassifier()

param_grid_rf = {'min_samples_split': [5,10,15],
                 'n_estimators': [100,200,300],
                 'max_depth': [10,20,25],
                 'max_features': [3,6,9]}


grid_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5,scoring='accuracy')
grid_rf.fit(X_train, y_train)
grid_search_rf = grid_rf.best_estimator_

grid_rf.best_params_

"""###XGBoost"""

xgb_clf = xgb.XGBClassifier()

# Define the hyperparameters for tuning
param_grid_xgb = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.1, 0.01, 0.2],
    'subsample': [0.5, 0.7, 1],
    'n_estimators': [80,100],
    'colsample_bytree': [0.3, 0.6, 1.0],
    'gamma': [0.5, 1,2],
}
# Initialize GridSearchCV
grid_xgb = GridSearchCV(estimator=xgb_clf, param_grid=param_grid_xgb, cv=5, scoring='accuracy', n_jobs=-1,verbose=2)

# Fit the model
grid_xgb.fit(X_train, y_train)

# Get the best model with optimal hyperparameters
best_xgb = grid_xgb.best_estimator_

# Display the best parameters
print(f"Best Parameters: {grid_xgb.best_params_}")

"""#Results"""

#Null accuracy
y.value_counts().head(1)/len(y)

def evaluate_models_with_auc(models, X_train, y_train, X_test, y_test):
    # Initialize a list to store the results
    results = []

    # Iterate over the models
    for model_name, model in models.items():
        # Predictions on the training set
        train_preds = model.predict(X_train)
        train_accuracy = accuracy_score(y_train, train_preds)

        # Predictions on the test set
        test_preds = model.predict(X_test)
        test_accuracy = accuracy_score(y_test, test_preds)
        test_recall = recall_score(y_test, test_preds)  # Recall score for binary classification

        # Confusion matrix
        tn, fp, fn, tp = confusion_matrix(y_test, test_preds).ravel()

        # Calculate AUC
        if hasattr(model, "predict_proba"):  # Check if the model supports predict_proba
            y_pred_prob = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class
        else:
            y_pred_prob = model.decision_function(X_test)  # For models like SVC
            y_pred_prob = (y_pred_prob - y_pred_prob.min()) / (y_pred_prob.max() - y_pred_prob.min())  # Normalize to [0,1]

        auc_value = roc_auc_score(y_test, y_pred_prob)
        f1 = f1_score(y_test, test_preds)

        # Append results to the list
        results.append({
            'Model': model_name,
            'Training Accuracy': train_accuracy,
            'Testing Accuracy': test_accuracy,
            'Recall': test_recall,
            'False Negatives': fn,
            'AUC': auc_value,
            'F1 Score': f1
        })

    # Convert results list to DataFrame
    results_df = pd.DataFrame(results)
    return results_df

rf_model = RandomForestClassifier(
  max_depth=15,
 max_features= 5,
 min_samples_split= 10,
 n_estimators= 100)

# Fit the model on the training data
rf_model.fit(X_train, y_train)

# Assuming best models are stored as best_knn, best_rf, best_gnb, etc.
models = {
    'Decision Tree': grid_dt,
    'Random Forest': grid_rf,
    'Forest 2': rf_model,
    'XGBoost': best_xgb,
}
models_dis={
    'Logistic Regression': grid_lr,
    'SVC': grid_svc,
    'Naive Bayes': grid_nb,
    'KNN': grid_knn,

}

# Call the function with your data
results_df1 = evaluate_models_with_auc(models, X_train, y_train, X_test, y_test)
results_df_dis1 = evaluate_models_with_auc(models_dis, X_train_scaled, y_train, X_test_scaled, y_test)

merged_df1 = pd.concat([results_df1, results_df_dis1], ignore_index=True)

merged_df1

